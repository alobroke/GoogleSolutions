{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f11e548-ee53-4233-a4ba-da5efecdb37c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68c8ff1-948a-4326-b2fe-463840744214",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m categories \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(data_dir)  \u001b[38;5;66;03m# List of class folders\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses:\u001b[39m\u001b[38;5;124m\"\u001b[39m, categories)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/'"
     ]
    }
   ],
   "source": [
    "data_dir = \"dataset/\"\n",
    "categories = os.listdir(data_dir)  # List of class folders\n",
    "print(\"Classes:\", categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21ba63-eafb-40ab-81e6-8fde8ea358a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78963605-243f-4993-be4b-e75b6a050251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe92648-80da-432d-b3a2-a32acc3edfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "model.save(\"sign_language_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35df2850-913d-422e-9830-91f1c4e30281",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mp_hands \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mhands\n\u001b[0;32m      2\u001b[0m hands \u001b[38;5;241m=\u001b[39m mp_hands\u001b[38;5;241m.\u001b[39mHands(max_num_hands\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      3\u001b[0m mp_draw \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_utils\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"sign_language_model.h5\")\n",
    "\n",
    "# Label Mapping\n",
    "label_map = dict(enumerate(categories))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(img_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_lms in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_lms, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        img_resized = cv2.resize(frame, (img_size, img_size)) / 255.0\n",
    "        img_resized = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "        prediction = model.predict(img_resized)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        text = label_map[predicted_class]\n",
    "\n",
    "        cv2.putText(frame, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Convert to Speech\n",
    "        tts = gTTS(text=text, lang='en')\n",
    "        tts.save(\"output.mp3\")\n",
    "        Audio(\"output.mp3\")\n",
    "\n",
    "    cv2.imshow(\"Sign Language Recognition\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd348ef-ac7a-4f39-a4c9-c9968603181e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
